# ‚ö° INFERENCIA EN TIEMPO REAL DE ALTA PERFORMANCE

## üìã **DESCRIPCI√ìN**

Sistema de inferencia en tiempo real optimizado para trading con arquitectura de baja latencia, manejo de m√∫ltiples modelos, streaming de datos y monitoreo de performance.

## ‚ú® **CARACTER√çSTICAS PRINCIPALES**

### **1. ARQUITECTURA DE BAJA LATENCIA**
- **Pool de modelos pre-cargados** en memoria
- **Cache de features** calculadas recientemente
- **Predicciones as√≠ncronas** con asyncio
- **Procesamiento en lotes** para m√∫ltiples s√≠mbolos

### **2. MANEJO DE M√öLTIPLES MODELOS**
- **Carga lazy** de modelos por s√≠mbolo/timeframe
- **Versionado autom√°tico**: cargar √∫ltimo modelo promovido
- **Fallback a modelo anterior** si el nuevo falla
- **Pool inteligente** con evicci√≥n LRU

### **3. STREAMING DE DATOS**
- **Conexi√≥n persistente** a DB con pooling
- **Trigger en nuevas barras** OHLCV
- **Batch processing** de m√∫ltiples s√≠mbolos
- **Cache de features** con TTL configurable

### **4. MONITOREO DE LATENCIA**
- **M√©tricas de tiempo** por etapa: carga, features, predicci√≥n
- **Alertas si latencia > 5 segundos**
- **Logging de performance** por s√≠mbolo
- **Dashboard de m√©tricas** en tiempo real

### **5. SISTEMA DE SALUD**
- **Health checks** cada minuto
- **Auto-restart** en caso de memory leaks
- **M√©tricas de CPU/memoria** del proceso
- **Alertas autom√°ticas** de recursos

### **6. CONFIGURACI√ìN ADAPTATIVA**
- **Ajuste autom√°tico** de batch size seg√∫n latencia
- **Escalado de workers** seg√∫n carga
- **Priorizaci√≥n por volumen** de trading
- **Configuraci√≥n din√°mica** de par√°metros

## üõ†Ô∏è **INSTALACI√ìN**

### **Dependencias adicionales:**
```bash
pip install asyncio psutil aiofiles aiohttp
```

### **Configuraci√≥n inicial:**
```python
from core.ml.inference.infer_realtime import create_inference_engine

# Crear motor con configuraci√≥n personalizada
config = {
    'max_latency_ms': 3000,  # 3 segundos m√°ximo
    'health_check_interval': 30,  # 30 segundos
    'cache_ttl_seconds': 180,  # 3 minutos
    'max_memory_mb': 1024,  # 1GB
    'model_pool_size': 20,
    'feature_cache_size': 500
}

engine = create_inference_engine(config)
```

## üöÄ **USO**

### **INICIO B√ÅSICO:**
```python
import asyncio
from core.ml.inference.infer_realtime import start_realtime_inference

# Iniciar sistema completo
asyncio.run(start_realtime_inference())
```

### **USO AVANZADO:**
```python
import asyncio
from core.ml.inference.infer_realtime import create_inference_engine

async def main():
    # Crear motor
    engine = create_inference_engine()
    
    # Iniciar en background
    inference_task = asyncio.create_task(engine.start())
    
    # Esperar inicializaci√≥n
    await asyncio.sleep(2)
    
    # Solicitar predicciones
    await engine.predict("BTCUSDT", "1m", 1)
    await engine.predict("ETHUSDT", "5m", 3)
    await engine.predict("ADAUSDT", "1h", 5)
    
    # Obtener m√©tricas
    metrics = engine.get_metrics()
    print(f"M√©tricas: {metrics}")
    
    # Cerrar
    inference_task.cancel()
    await inference_task

asyncio.run(main())
```

### **PREDICCIONES EN LOTE:**
```python
async def batch_predictions(engine, symbols, timeframes, horizons):
    """Realizar predicciones en lote"""
    tasks = []
    
    for symbol in symbols:
        for tf in timeframes:
            for horizon in horizons:
                task = engine.predict(symbol, tf, horizon)
                tasks.append(task)
    
    # Ejecutar todas las predicciones en paralelo
    await asyncio.gather(*tasks)
```

## ‚öôÔ∏è **CONFIGURACI√ìN**

### **PAR√ÅMETROS PRINCIPALES:**
```python
PERFORMANCE_CONFIG = {
    'max_latency_ms': 5000,        # Latencia m√°xima permitida
    'health_check_interval': 60,    # Intervalo de health check (segundos)
    'cache_ttl_seconds': 300,      # TTL del cache de features
    'max_memory_mb': 2048,         # L√≠mite de memoria (MB)
    'batch_size_initial': 10,      # Tama√±o inicial de lote
    'batch_size_max': 100,         # Tama√±o m√°ximo de lote
    'workers_initial': 2,          # Workers iniciales
    'workers_max': 8,              # Workers m√°ximos
    'model_pool_size': 50,         # Tama√±o del pool de modelos
    'feature_cache_size': 1000     # Tama√±o del cache de features
}
```

### **CONFIGURACI√ìN DE BASE DE DATOS:**
```python
# Pool de conexiones optimizado
DB_CONFIG = {
    'pool_size': 20,
    'max_overflow': 30,
    'pool_pre_ping': True,
    'pool_recycle': 3600,
    'echo': False
}
```

## üìä **MONITOREO Y M√âTRICAS**

### **M√âTRICAS DE PERFORMANCE:**
```python
metrics = engine.get_metrics()

print(f"Predicciones totales: {metrics['performance']['total_predictions']}")
print(f"Latencia promedio: {metrics['performance']['avg_latency_ms']:.1f}ms")
print(f"Latencia m√°xima: {metrics['performance']['max_latency_ms']:.1f}ms")
print(f"Tasa de error: {metrics['performance']['error_rate']:.1f}%")
print(f"Hit rate cache: {metrics['performance']['cache_hit_rate']:.1f}%")
```

### **M√âTRICAS DEL SISTEMA:**
```python
print(f"Memoria: {metrics['system']['memory_usage_mb']:.1f}MB")
print(f"CPU: {metrics['system']['cpu_usage_percent']:.1f}%")
print(f"Modelos cargados: {metrics['system']['models_loaded']}")
print(f"√öltimo health check: {metrics['system']['last_health_check']}")
```

### **M√âTRICAS DEL POOL DE MODELOS:**
```python
pool_stats = metrics['model_pool']
print(f"Modelos en pool: {pool_stats['total_models']}/{pool_stats['max_size']}")

for model_key, model_info in pool_stats['models'].items():
    print(f"  {model_key}: {model_info['predictions_count']} pred, "
          f"{model_info['avg_latency_ms']:.1f}ms avg")
```

### **M√âTRICAS DEL CACHE:**
```python
cache_stats = metrics['feature_cache']
print(f"Entradas en cache: {cache_stats['total_entries']}")
print(f"Hit rate: {cache_stats['hit_rate_percent']:.1f}%")
print(f"TTL: {cache_stats['ttl_seconds']}s")
```

## üîß **ARQUITECTURA INTERNA**

### **COMPONENTES PRINCIPALES:**

1. **RealtimeInferenceEngine**: Motor principal
2. **ModelPool**: Pool de modelos pre-cargados
3. **FeatureCacheManager**: Cache de features calculadas
4. **PerformanceMetrics**: M√©tricas del sistema

### **FLUJO DE PREDICCI√ìN:**

1. **Solicitud** ‚Üí `predict()` ‚Üí Cola de predicciones
2. **Procesador** ‚Üí Obtener modelo del pool
3. **Features** ‚Üí Verificar cache ‚Üí Calcular si necesario
4. **Predicci√≥n** ‚Üí Modelo + Features ‚Üí Resultado
5. **Resultado** ‚Üí Guardar en DB ‚Üí Logging

### **TAREAS AS√çNCRONAS:**

- `_health_check_loop()`: Monitoreo de salud
- `_prediction_processor()`: Procesamiento de predicciones
- `_result_processor()`: Manejo de resultados
- `_metrics_collector()`: Recolecci√≥n de m√©tricas

## üß™ **PRUEBAS**

### **EJECUTAR PRUEBAS:**
```bash
python test_realtime_inference.py
```

### **PRUEBAS INCLUIDAS:**
1. **Inferencia B√°sica**: Carga y predicci√≥n b√°sica
2. **M√©tricas de Performance**: Medici√≥n de latencia
3. **Funcionalidad de Cache**: Verificaci√≥n de cache hit/miss
4. **Monitoreo de Salud**: Health checks y alertas
5. **Manejo de Errores**: Robustez ante errores

### **PRUEBA MANUAL:**
```python
import asyncio
from core.ml.inference.infer_realtime import create_inference_engine

async def test_manual():
    engine = create_inference_engine()
    
    # Iniciar
    task = asyncio.create_task(engine.start())
    await asyncio.sleep(2)
    
    # Probar predicciones
    await engine.predict("BTCUSDT", "1m", 1)
    await asyncio.sleep(1)
    
    # Ver m√©tricas
    metrics = engine.get_metrics()
    print(metrics)
    
    # Cerrar
    task.cancel()
    await task

asyncio.run(test_manual())
```

## üö® **SOLUCI√ìN DE PROBLEMAS**

### **LATENCIA ALTA:**
```python
# Reducir batch size
config['batch_size_initial'] = 5
config['batch_size_max'] = 20

# Aumentar workers
config['workers_initial'] = 4
config['workers_max'] = 12

# Reducir TTL del cache
config['cache_ttl_seconds'] = 60
```

### **MEMORIA ALTA:**
```python
# Reducir pool de modelos
config['model_pool_size'] = 10

# Reducir cache de features
config['feature_cache_size'] = 200

# Reducir l√≠mite de memoria
config['max_memory_mb'] = 512
```

### **ERRORES DE MODELO:**
```python
# Verificar que hay modelos promovidos
# Verificar rutas de artefactos
# Verificar permisos de archivos
```

### **CACHE NO FUNCIONA:**
```python
# Verificar TTL
config['cache_ttl_seconds'] = 300

# Verificar tama√±o
config['feature_cache_size'] = 1000

# Verificar logs de cache
```

## üìà **RENDIMIENTO ESPERADO**

### **LATENCIA:**
- **Predicci√≥n simple**: 10-50ms
- **Con cache hit**: 5-20ms
- **Con cache miss**: 50-200ms
- **M√∫ltiples s√≠mbolos**: 100-500ms

### **THROUGHPUT:**
- **Predicciones por segundo**: 100-1000
- **S√≠mbolos simult√°neos**: 10-50
- **Timeframes simult√°neos**: 5-20

### **RECURSOS:**
- **Memoria**: 100-500MB
- **CPU**: 10-50%
- **Conexiones DB**: 5-20

## üéØ **BENEFICIOS**

1. **Baja Latencia**: Predicciones en milisegundos
2. **Alta Disponibilidad**: Sistema robusto y resiliente
3. **Escalabilidad**: Maneja m√∫ltiples s√≠mbolos/timeframes
4. **Eficiencia**: Cache inteligente y pooling
5. **Monitoreo**: M√©tricas completas en tiempo real
6. **Flexibilidad**: Configuraci√≥n adaptativa

## üìÅ **ARCHIVOS GENERADOS**

### **LOGS:**
- `logs/infer_realtime.log` - Log principal
- Logs de performance por s√≠mbolo
- Alertas de latencia y recursos

### **CACHE:**
- Cache de modelos en memoria
- Cache de features en memoria
- Estad√≠sticas de hit/miss

### **BASE DE DATOS:**
- `trading.agentpreds` - Predicciones guardadas
- M√©tricas de performance
- Logs de errores

## üîÑ **INTEGRACI√ìN**

### **CON SISTEMA DE TRADING:**
```python
# Integrar con sistema de trading
from core.ml.inference.infer_realtime import create_inference_engine

class TradingSystem:
    def __init__(self):
        self.inference_engine = create_inference_engine()
    
    async def start(self):
        # Iniciar inferencia
        self.inference_task = asyncio.create_task(
            self.inference_engine.start()
        )
    
    async def get_prediction(self, symbol, timeframe, horizon):
        # Solicitar predicci√≥n
        await self.inference_engine.predict(symbol, timeframe, horizon)
        
        # Procesar resultado (implementar callback)
        pass
```

### **CON DASHBOARD:**
```python
# Integrar con dashboard web
from flask import Flask, jsonify

app = Flask(__name__)

@app.route('/api/metrics')
def get_metrics():
    return jsonify(engine.get_metrics())

@app.route('/api/predict')
def predict():
    symbol = request.args.get('symbol')
    timeframe = request.args.get('timeframe')
    horizon = int(request.args.get('horizon', 1))
    
    asyncio.create_task(
        engine.predict(symbol, timeframe, horizon)
    )
    
    return jsonify({'status': 'prediction_requested'})
```

¬°El sistema de inferencia en tiempo real est√° listo para trading de alta frecuencia! ‚ö°üöÄüìä
