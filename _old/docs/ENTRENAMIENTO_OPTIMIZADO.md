# üöÄ ENTRENAMIENTO OPTIMIZADO

## üìã **DESCRIPCI√ìN**

Sistema de entrenamiento optimizado para datasets grandes con gesti√≥n avanzada de memoria, validaci√≥n walk-forward robusta y monitoreo en tiempo real.

## ‚ú® **CARACTER√çSTICAS PRINCIPALES**

### **1. GESTI√ìN DE MEMORIA**
- **Procesamiento por chunks** de 50k filas
- **Liberaci√≥n expl√≠cita** de memoria con `gc.collect()`
- **Monitoreo de RAM** con `psutil`
- **L√≠mite de memoria** configurable (85% por defecto)

### **2. VALIDACI√ìN WALK-FORWARD**
- **TimeSeriesSplit** con embargo temporal de 30 minutos
- **M√≠nimo 5 folds** para validaci√≥n robusta
- **M√©tricas promediadas** entre folds
- **Prevenci√≥n de data leakage**

### **3. LOGGING DETALLADO**
- **Progreso cada 10%** del entrenamiento
- **M√©tricas intermedias** (AUC, Brier) por fold
- **Tiempo estimado** restante
- **Uso de memoria** actual

### **4. EARLY STOPPING**
- **Parar si AUC no mejora** en 3 folds consecutivos
- **Guardar mejor modelo** hasta el momento
- **Prevenci√≥n de overfitting**

### **5. SISTEMA DE CHECKPOINTS**
- **Guardar estado** cada fold completado
- **Reanudar desde** √∫ltimo checkpoint
- **Recuperaci√≥n autom√°tica** de fallos

### **6. CONFIGURACI√ìN ADAPTATIVA**
- **Max_iter autom√°tico** seg√∫n tama√±o del dataset
- **Detecci√≥n de GPU** si est√° disponible
- **Escalado autom√°tico** de batch size

## üõ†Ô∏è **INSTALACI√ìN**

### **1. Instalar dependencias:**
```bash
pip install -r requirements.txt
pip install psutil>=5.9.0
```

### **2. Configurar sistema:**
```bash
python core/ml/training/configure_optimized_training.py --check-requirements --create-logging
```

### **3. Probar instalaci√≥n:**
```bash
python test_optimized_training.py
```

## üöÄ **USO**

### **ENTRENAMIENTO B√ÅSICO:**
```bash
python -m core.ml.training.train_direction \
    --symbol BTCUSDT \
    --tf 1m \
    --horizon 1 \
    --max-bars 0
```

### **ENTRENAMIENTO OPTIMIZADO:**
```bash
python -m core.ml.training.train_direction \
    --symbol BTCUSDT \
    --tf 1m \
    --horizon 1 \
    --max-bars 0 \
    --n-splits 5 \
    --embargo-minutes 30 \
    --chunk-size 50000 \
    --use-gpu
```

### **REANUDAR ENTRENAMIENTO:**
```bash
python -m core.ml.training.train_direction \
    --symbol BTCUSDT \
    --tf 1m \
    --horizon 1 \
    --resume
```

## üìä **MONITOREO**

### **MONITOR EN TIEMPO REAL:**
```bash
python core/ml/monitoring/monitor_training_progress.py \
    --symbol BTCUSDT \
    --tf 1m \
    --horizon 1 \
    --refresh 30
```

### **RESUMEN R√ÅPIDO:**
```bash
python core/ml/monitoring/monitor_training_progress.py \
    --symbol BTCUSDT \
    --tf 1m \
    --horizon 1 \
    --summary
```

## ‚öôÔ∏è **CONFIGURACI√ìN**

### **ARCHIVO DE CONFIGURACI√ìN:**
```yaml
# config/ml/training.yaml
training:
  optimized:
    enabled: true
    chunk_size: 50000
    memory_threshold: 0.85
    n_splits: 5
    embargo_minutes: 30
    early_stopping_patience: 3
    adaptive_max_iter: true
    use_gpu: false
    checkpoint_enabled: true
```

### **VARIABLES DE ENTORNO:**
```bash
# config/training.env
BT_OPTIMIZED_TRAINING=true
BT_CHUNK_SIZE=50000
BT_MEMORY_THRESHOLD=0.85
BT_N_SPLITS=5
BT_EMBARGO_MINUTES=30
BT_USE_GPU=false
```

## üìÅ **ARCHIVOS GENERADOS**

### **CHECKPOINTS:**
- `logs/checkpoint_{symbol}_{tf}_H{horizon}.pkl`

### **MODELOS:**
- `artifacts/direction/{symbol}_{tf}_H{horizon}_logreg_optimized.pkl`

### **LOGS:**
- `logs/train_direction_optimized.log`
- `logs/train_direction.log`

## üîß **PAR√ÅMETROS AVANZADOS**

### **GESTI√ìN DE MEMORIA:**
- `--chunk-size`: Tama√±o de chunk (default: 50000)
- `--memory-threshold`: L√≠mite de memoria (default: 0.85)

### **VALIDACI√ìN:**
- `--n-splits`: N√∫mero de folds (default: 5)
- `--embargo-minutes`: Embargo temporal (default: 30)

### **ENTRENAMIENTO:**
- `--use-gpu`: Usar GPU si est√° disponible
- `--resume`: Reanudar desde checkpoint
- `--max-bars`: L√≠mite de barras (0 = todo)

## üìä **M√âTRICAS MONITOREADAS**

### **POR FOLD:**
- **AUC**: Area Under Curve
- **Brier**: Brier Score Loss
- **Accuracy**: Precisi√≥n
- **Tiempo**: Tiempo de entrenamiento

### **SISTEMA:**
- **Memoria**: Uso de RAM
- **CPU**: Uso de procesador
- **GPU**: Uso de GPU (si disponible)

## üö® **SOLUCI√ìN DE PROBLEMAS**

### **MEMORIA INSUFICIENTE:**
```bash
# Reducir chunk size
--chunk-size 25000

# Reducir n√∫mero de folds
--n-splits 3
```

### **ENTRENAMIENTO LENTO:**
```bash
# Usar GPU si est√° disponible
--use-gpu

# Reducir dataset para pruebas
--max-bars 10000
```

### **CHECKPOINT CORRUPTO:**
```bash
# Eliminar checkpoint y reiniciar
rm logs/checkpoint_*.pkl
```

## üìà **RENDIMIENTO ESPERADO**

### **DATASET PEQUE√ëO (< 10k filas):**
- **Tiempo**: 2-5 minutos
- **Memoria**: < 2GB
- **Folds**: 3-5

### **DATASET MEDIANO (10k-100k filas):**
- **Tiempo**: 10-30 minutos
- **Memoria**: 2-8GB
- **Folds**: 5-7

### **DATASET GRANDE (> 100k filas):**
- **Tiempo**: 30+ minutos
- **Memoria**: 8+ GB
- **Folds**: 5-10

## üîÑ **INTEGRACI√ìN CON RUNNER**

El entrenamiento optimizado se integra autom√°ticamente con el runner diario:

```python
# En runner.py
run_cmd([
    "python", "-m", "core.ml.training.train_direction",
    "--symbol", symbol, "--tf", tf,
    "--horizon", str(horizon),
    "--from", f_train, "--to", t_train,
    "--seed", str(seed),
    "--max-bars", "0",  # Usar todo el hist√≥rico
    "--n-splits", "5",  # 5 folds
    "--embargo-minutes", "30",  # 30 min embargo
    "--chunk-size", "50000"  # 50k filas por chunk
])
```

## üìö **EJEMPLOS DE USO**

### **ENTRENAMIENTO COMPLETO:**
```bash
# BTCUSDT 1m con todo el hist√≥rico
python -m core.ml.training.train_direction \
    --symbol BTCUSDT --tf 1m --horizon 1 \
    --max-bars 0 --n-splits 5 --use-gpu
```

### **ENTRENAMIENTO R√ÅPIDO:**
```bash
# Prueba r√°pida con dataset peque√±o
python -m core.ml.training.train_direction \
    --symbol BTCUSDT --tf 1m --horizon 1 \
    --max-bars 5000 --n-splits 3 --chunk-size 1000
```

### **MONITOREO CONTINUO:**
```bash
# Monitor en segundo plano
nohup python core/ml/monitoring/monitor_training_progress.py \
    --symbol BTCUSDT --tf 1m --horizon 1 \
    --refresh 60 > monitor.log 2>&1 &
```

## üéØ **BENEFICIOS**

1. **Escalabilidad**: Maneja datasets de cualquier tama√±o
2. **Robustez**: Validaci√≥n walk-forward robusta
3. **Eficiencia**: Gesti√≥n optimizada de memoria
4. **Confiabilidad**: Sistema de checkpoints
5. **Monitoreo**: Visibilidad completa del proceso
6. **Flexibilidad**: Configuraci√≥n adaptativa
7. **Recuperaci√≥n**: Capacidad de reanudar entrenamientos
